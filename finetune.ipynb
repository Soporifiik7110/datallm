{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Llama 7b using your data\n",
    "\n",
    "In this notebook, we'll walk you through the steps to fine-tune Llama using your dataset. \n",
    "Follow along by running each cell in order!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Installation\n",
    "\n",
    "Before we get started, let's ensure we have all the necessary packages installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install autotrain-advanced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Autotrain\n",
    "Required if you are using Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!autotrain setup --update-torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Autotrain LLM help tool (optional)\n",
    "If you want to learn more about what command-line flags are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!autotrain llm -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log into Hugging Face Hub\n",
    "\n",
    "To make sure the model can be uploaded and shared via the Hugging Face platform, it's necessary to log in to the Hugging Face hub. \n",
    "\n",
    "#### Locating Hugging Face token\n",
    "You can create User Access Tokens at this URL: https://huggingface.co/settings/tokens\n",
    "\n",
    "Step: \n",
    "1. Navigate to this URL \n",
    "2. Create a `write` token and copy it to your clipboard\n",
    "3. Run the code below and enter your token\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Autotrain command\n",
    "\n",
    "- `!autotrain`: Command executed in environments like a Jupyter notebook to run shell commands directly. `autotrain` is an automatic training utility or script.\n",
    "\n",
    "- `llm`: A sub-command or argument specifying the type of task\n",
    "\n",
    "- `--train`: Initiates the training process.\n",
    "\n",
    "- `--project_name my-llm`: Sets the name of the project or task to \"my-llm\".\n",
    "\n",
    "- `--model abhishek/llama-2-7b-hf-small-shards`: Specifies the model that is hosted on Hugging Face named \"llama-2-7b-hf-small-shards\" under the \"abhishek\".\n",
    "\n",
    "- `--data_path .`: The path to the dataset for training. The \".\" refers to the current directory. The `training.csv` file needs to be located in this directory. \n",
    "\n",
    "- `--use_peft`: I'm not sure what this does\n",
    "\n",
    "- `--use_int4`: Use of INT4 quantization to reduce model size and speed up inference times at the cost of some precision.\n",
    "\n",
    "- `--learning_rate 2e-4`: Sets the learning rate for training to 0.0002.\n",
    "\n",
    "- `--train_batch_size 12`: Sets the batch size for training to 12.\n",
    "\n",
    "- `--num_train_epochs 3`: The training process will iterate over the dataset 3 times.\n",
    "\n",
    "- `--trainer sft`: Sets the trainer or training algorithm to \"sft\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!autotrain llm --train --project_name my-llm --model abhishek/llama-2-7b-hf-small-shards --data_path . --use_peft --use_int4 --learning_rate 2e-4 --train_batch_size 12 --num_train_epochs 3 --trainer sft"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
