{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Llama 2 7b with AutoTrain\n",
    "\n",
    "In this notebook, we'll walk you through the steps to fine-tune Llama using your dataset. \n",
    "Follow along by running each cell in order!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Installation\n",
    "\n",
    "Before we get started, let's ensure we have all the necessary packages installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install autotrain-advanced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Autotrain\n",
    "Required if you are using Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!autotrain setup --update-torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Hugging Face for inference\n",
    "#### Logging to hugging face\n",
    "\n",
    "To make sure the model can be uploaded and shared via the Hugging Face platform, it's necessary to log in to the Hugging Face hub. \n",
    "\n",
    "#### Locating Hugging Face token\n",
    "You can create User Access Tokens at this URL: https://huggingface.co/settings/tokens\n",
    "\n",
    "Step: \n",
    "1. Navigate to this URL \n",
    "2. Create a `write` token and copy it to your clipboard\n",
    "3. Run the code below and enter your token\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of Autotrain command\n",
    "\n",
    "Short overview of what the command flags do. \n",
    "\n",
    "- `!autotrain`: Command executed in environments like a Jupyter notebook to run shell commands directly. `autotrain` is an automatic training utility. \n",
    "\n",
    "- `llm`: A sub-command or argument specifying the type of task\n",
    "\n",
    "- `--train`: Initiates the training process.\n",
    "\n",
    "- `--project_name`: Sets the name of the project \n",
    "\n",
    "- `--model abhishek/llama-2-7b-hf-small-shards`: Specifies original model that is hosted on Hugging Face named \"llama-2-7b-hf-small-shards\" under the \"abhishek\".\n",
    "\n",
    "- `--data_path .`: The path to the dataset for training. The \".\" refers to the current directory. The `train.csv` file needs to be located in this directory. \n",
    "\n",
    "- `--use_int4`: Use of INT4 quantization to reduce model size and speed up inference times at the cost of some precision.\n",
    "\n",
    "- `--learning_rate 2e-4`: Sets the learning rate for training to 0.0002.\n",
    "\n",
    "- `--train_batch_size 12`: Sets the batch size for training to 12.\n",
    "\n",
    "- `--num_train_epochs 3`: The training process will iterate over the dataset 3 times.\n",
    "\n",
    "### Steps needed before running\n",
    "\n",
    "1. After `--project_name` replace `*enter-a-project-name*` with the name that you'd like to call the project\n",
    "2. After `--repo_id` replace `*username*/*repository*`. Replace `*username*` with your Hugging Face username and `*repository*` with the repository name you'd like it to be created under. You don't need to create this repository before hand, it will automatically be created and uploaded to once the training is completed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!autotrain llm --train --project_name *enter-a-project-name* --model abhishek/llama-2-7b-hf-small-shards --data_path . --use_peft --use_int4 --learning_rate 2e-4 --train_batch_size 12 --num_train_epochs 3 --trainer sft --push_to_hub --repo_id *username*/*repository*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completed ðŸŽ‰\n",
    "After the command above is completed your Model will be uploaded to Hugging Face.\n",
    "\n",
    "#### Learn more about AutoTrain (optional)\n",
    "If you want to learn more about what command-line flags are available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!autotrain llm -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
